# ğŸ©º ClinicalLens-Echo

**ClinicalLens-Echo** is an AI-powered clinical assistant that simulates doctorâ€“patient interactions using **speech recognition**, **text-to-speech**, and **multimodal AI reasoning**.  
It supports patient voice input, doctor voice output, and optional image-based clinical analysis.

---

## âœ¨ Features

- ğŸ¤ **Patient Voice Input**
  - Records patient speech
  - Transcribes audio using AI speech recognition
- ğŸ§‘â€âš•ï¸ **Doctor Voice Output**
  - Converts AI-generated responses into natural speech
- ğŸ§  **AI Reasoning Core**
  - Processes text, audio, and images
  - Generates medical-style responses
- ğŸ–¼ï¸ **Image Understanding**
  - Encodes and analyzes images for multimodal reasoning
- ğŸŒ **Extensible Architecture**
  - Easy to integrate with Gradio or other web frameworks

---

## ğŸ“‚ Project Structure

```
ClinicalLens-Echo/
â”‚
â”œâ”€â”€ brain.py
â”œâ”€â”€ patient_voice.py
â”œâ”€â”€ doctor_voice.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ› ï¸ Requirements

- Python **3.9+**
- Working microphone
- API keys for supported AI services

Install dependencies:

```bash
pip install -r requirements.txt
```

---

## ğŸ”‘ Environment Variables

Create a `.env` file in the project root:

```env
GROQ_API_KEY=your_groq_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here
ELEVENLABS_API_KEY=your_elevenlabs_api_key_here
```

---

## ğŸš€ Usage

```bash
python patient_voice.py
python brain.py
python doctor_voice.py
```

---

## âš ï¸ Disclaimer

This project is for **educational and research purposes only** and does **not** provide medical advice.

---

## ğŸ“„ License

MIT License
